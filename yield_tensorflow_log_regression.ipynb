{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_helper_functions import aws_helper_functions\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sk_metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "num_classes = 1\n",
    "num_features = 64\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "batch_size = 200\n",
    "display_step = 50\n",
    "\n",
    "def _get_table_data(basetable=''):\n",
    "    raw_basetable = pd.read_csv(basetable)\n",
    "    df = raw_basetable\n",
    "    df = df[~df['grade'].isin(['PK', 'Not In School'])]\n",
    "    df = df[~df['grade'].isnull()]\n",
    "    df['scholar_grade'] = np.where(df['grade']=='K','0',df['grade']).astype(int)\n",
    "    df['latitude'] = df['students_home__latitude__s']\n",
    "    df['longitude'] = df['students_home__longitude__s']\n",
    "    df['school'] = df['accepted_school']\n",
    "    df = _get_commute_time(_retrieve_nearest_census_tract_numbers(df,local_mode=True),local_mode=True)\n",
    "    df['intercept'] = 1\n",
    "    df['es_school'] = df['scholar_grade'].isin(np.arange(0,5)).astype(int)\n",
    "    df['ms_school'] = df['scholar_grade'].isin(np.arange(5,6)).astype(int)\n",
    "    df['log_commute'] = np.log(df['commute_time'])\n",
    "    df['log_commute_square'] = df['log_commute'] ** 2\n",
    "    df['log_commute_third'] = df['log_commute'] ** 3\n",
    "    df = df[['intercept','yield','uniform_ordered','accepted_first_rank','had_enrolled_sib','ell_status','homeless_status','es_school','ms_school','orientation_rsvp','virtual_event_attended','in_person_event_attended',\n",
    "            'scholar_grade','commute_time',\n",
    "            'log_commute','log_commute_square','log_commute_third',\n",
    "            'school','utm_source_bucketing']]\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def _retrieve_nearest_census_tract_numbers(df, local_mode=''):\n",
    "    # retrive census tract information from redshift\n",
    "    df_census = aws_helper_functions.read_from_redshift('SELECT * FROM raw_data_science.raw_commute_census_tracts_lat_long', local_mode=local_mode)\n",
    "    # Create a BallTree for the census tract latitudes and longitudes\n",
    "    tree = BallTree(df_census[['lat_orig', 'long_orig']].values, leaf_size=40)\n",
    "    \n",
    "    #drop rows in df where students_home__latitude__s or students_home__longitude__s is null\n",
    "    #df = df.dropna(subset=['latitude', 'longitude'])\n",
    "    df['latitude'] = np.where(df['latitude'].isna()==True, 40.776676, df['latitude'])\n",
    "    df['longitude'] = np.where(df['longitude'].isna()==True, -73.971321, df['longitude'])\n",
    "    \n",
    "    distances, indices = tree.query(df[['latitude', 'longitude']].values, k=1)\n",
    "    df.loc[:, 'boro_int'] = df_census.loc[indices.flatten(), 'boro_int'].values.copy()\n",
    "    df.loc[:, 'census_tract_int'] = df_census.loc[indices.flatten(), 'census_tract_int'].values.copy()\n",
    "    return df\n",
    "\n",
    "def _get_commute_time(df, local_mode=''):\n",
    "    #retrieve school-census tract commute times from redshift\n",
    "    df_commutes = aws_helper_functions.read_from_redshift('SELECT * FROM raw_data_science.raw_commute_census_tracts_to_schools', local_mode=local_mode)\n",
    "    \n",
    "    schools = _get_schools()\n",
    "    df_commutes = _replace_with_keys(df_commutes, 'school', schools)\n",
    "    #set df_commutes.time_walking_min, time_transit_min, and time_driving_min to numeric\n",
    "    df_commutes['time_walking_min'] = pd.to_numeric(df_commutes['time_walking_min'], errors='coerce')\n",
    "    df_commutes['time_transit_min'] = pd.to_numeric(df_commutes['time_transit_min'], errors='coerce')\n",
    "    df_commutes['time_driving_min'] = pd.to_numeric(df_commutes['time_driving_min'], errors='coerce')\n",
    "    \n",
    "    df_commutes['commute_time'] = df_commutes[['time_walking_min', 'time_transit_min']].min(axis=1)\n",
    "    df_commutes = df_commutes[['boro_int', 'census_tract_int', 'school', 'commute_time']]\n",
    "    \n",
    "    df = df.merge(df_commutes, how='left', on=['boro_int', 'census_tract_int', 'school'])\n",
    "    df['commute_time'] = np.where(df['commute_time']>120,30,df['commute_time'])\n",
    "    return df\n",
    "\n",
    "def _get_schools():\n",
    "    schools = {\n",
    "        'SA Bed-Stuy 2': 'BED-STUY2',\n",
    "        'SA Bed-Stuy': 'BED-STUY2',\n",
    "        'SA Bed-Stuy Middle School': 'BED-STUY_MIDDLE_SCHOOL',\n",
    "        'SA Bensonhurst': 'BENSONHURST',\n",
    "        'SA Bergen Beach':'BERGEN_BEACH',\n",
    "        'SA Bronx 1 Middle School': 'BRONX1',\n",
    "        'SA Bronx 1': 'BRONX1',\n",
    "        'SA Bronx Middle School': 'BRONX_MIDDLE_SCHOOL',\n",
    "        'SA Bronx 2': 'BRONX2',\n",
    "        'SA Bronx 2 Middle School': 'BRONX2_MIDDLE_SCHOOL',\n",
    "        'SA Bronx 3': 'BRONX3',\n",
    "        'SA Bronx 4': 'BRONX4',\n",
    "        'SA Bronx 5': 'BRONX5',\n",
    "        'SA Bronx 5 Upper': 'BRONX5',\n",
    "        'SA Bronx 5 Lower': 'BRONX5',\n",
    "        'SA Bushwick': 'BUSHWICK',\n",
    "        'SA Cobble Hill': 'COBBLE_HILL',\n",
    "        'SA Crown Heights': 'CROWN_HEIGHTS',\n",
    "        'SA Ditmas Park Middle School': 'DITMAS_PARK_MIDDLE_SCHOOL',\n",
    "        'SA East Flatbush Middle School': 'EAST_FLATBUSH_MIDDLE_SCHOOL',\n",
    "        'SA Far Rockaway': 'FAR_ROCKAWAY',\n",
    "        'SA Far Rockaway Middle School': 'FAR_ROCKAWAY_MIDDLE_SCHOOL',\n",
    "        'SA Flatbush': 'FLATBUSH',\n",
    "        'SA Hamilton Heights Middle School': 'HARLEM6',\n",
    "        'SA Harlem 1': 'HARLEM1',\n",
    "        'SA Harlem 2': 'HARLEM2',\n",
    "        'SA Harlem 3': 'HARLEM3',\n",
    "        'SA Harlem 4': 'HARLEM4',\n",
    "        'SA Harlem 5': 'HARLEM5',\n",
    "        'SA Harlem 6': 'HARLEM6',\n",
    "        'SA Harlem East': 'HARLEM_EAST',\n",
    "        'SA Harlem East Middle School': 'HARLEM_EAST',\n",
    "        'SA Harlem North Central': 'HARLEM_NORTH_CENTRAL',\n",
    "        'SA Harlem North Central Middle School': 'HARLEM_NORTH_CENTRAL',\n",
    "        'SA Harlem West': 'HARLEM_WEST',\n",
    "        'SA Harlem West Middle School': 'HARLEM_WEST',\n",
    "        'SA Harlem North West': 'HARLEM_NORTH_WEST',\n",
    "        'SA Harlem North West Middle School': 'HARLEM_NORTH_WEST',\n",
    "        'SA Hells Kitchen': 'HELLS_KITCHEN',\n",
    "        'SA Hell\\'s Kitchen': 'HELLS_KITCHEN',\n",
    "        'SA High School of the Liberal Arts - Manhattan': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_MANHATTAN',\n",
    "        'SA High School of the Liberal Arts-Manhattan': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_MANHATTAN',\n",
    "        'SA High School of the Liberal Arts - Harlem': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_HARLEM',\n",
    "        'SA High School of the Liberal Arts-Harlem': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_HARLEM',\n",
    "        'SA High School of the Liberal Arts - Brooklyn': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_BROOKLYN',\n",
    "        'SA High School of the Liberal Arts-Brooklyn': 'HIGH_SCHOOL_OF_THE_LIBERAL_ARTS_-_BROOKLYN',\n",
    "        'SA Hudson Yards': 'HUDSON_YARDS',\n",
    "        'SA Hudson Yards Middle School': 'HUDSON_YARDS_MIDDLE_SCHOOL',\n",
    "        'SA Kingsbridge Heights': 'KINGSBRIDGE_HEIGHTS',\n",
    "        'SA Lafayette Middle School': 'LAFAYETTE_MIDDLE_SCHOOL',\n",
    "        'SA Midtown West Middle School': 'MIDTOWN_WEST',\n",
    "        'SA Myrtle Middle School': 'MYRTLE_MIDDLE_SCHOOL',\n",
    "        'SA Norwood': 'NORWOOD',\n",
    "        'SA Ozone Park Middle School': 'OZONE_PARK_MIDDLE_SCHOOL',\n",
    "        'SA Prospect Heights': 'PROSPECT_HEIGHTS',\n",
    "        'SA Queens Village': 'QUEENS_VILLAGE',\n",
    "        'SA Rosedale': 'ROSEDALE',\n",
    "        'SA Rockaway Park Middle School': 'ROCKAWAY_PARK_MIDDLE_SCHOOL',\n",
    "        'SA South Jamaica': 'SOUTH_JAMAICA',\n",
    "        'SA Sheepshead Bay': 'SHEEPSHEAD_BAY',\n",
    "        'SA Springfield Gardens Middle School': 'SPRINGFIELD_GARDENS',\n",
    "        'SA Springfield Gardens MS': 'SPRINGFIELD_GARDENS',\n",
    "        'SA Springfield Gardens': 'SPRINGFIELD_GARDENS',\n",
    "        'SA Union Square': 'UNION_SQUARE',\n",
    "        'SA Upper West': 'UPPER_WEST',\n",
    "        'SA Washington Heights': 'WASHINGTON_HEIGHTS',\n",
    "        'SA Williamsburg': 'WILLIAMSBURG',\n",
    "        }\n",
    "    return schools\n",
    "\n",
    "def _replace_with_keys(df, column, dictionary):\n",
    "    new_df = pd.DataFrame()\n",
    "    for key, value in dictionary.items():\n",
    "        temp_df = df[df[column] == value].copy()\n",
    "        temp_df[column] = key\n",
    "        new_df = pd.concat([new_df, temp_df])\n",
    "    return new_df\n",
    "\n",
    "def set_predictors(current_predictors):\n",
    "    predictors = current_predictors\n",
    "    return predictors\n",
    "\n",
    "def set_target(current_target):\n",
    "    target = current_target\n",
    "    return target\n",
    "\n",
    "def setup_training_data(df, predictors, target):\n",
    "    X = df[predictors]\n",
    "    Y = df[target]\n",
    "    return X, Y\n",
    "\n",
    "def test_train_split(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def features_to_array(df, num_features=num_features):\n",
    "    array = np.array(df, np.float32).reshape([-1, num_features])\n",
    "    return array\n",
    "\n",
    "def classes_to_array(df, num_features=num_features):\n",
    "    array = np.array(df, np.float32).reshape([-1, num_classes])\n",
    "    return array\n",
    "\n",
    "def array_to_tensor(x_train, y_train, batch_size = batch_size):\n",
    "    train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train)).repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "    return train_data\n",
    "\n",
    "def set_weight(num_features = num_features, num_classes = num_classes):\n",
    "    W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
    "    return W\n",
    "\n",
    "def set_bias(num_classes = num_classes):\n",
    "    b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\n",
    "    return b\n",
    "\n",
    "# Logistic regression (Wx + b).\n",
    "def logistic_regression(x):\n",
    "    # Apply softmax to normalize the logits to a probability distribution.\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "# Cross-Entropy loss function.ß\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # Encode label to a one hot vector.\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    # Compute cross-entropy.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "# Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "# Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = _get_table_data('train_basetable.csv')\n",
    "\n",
    "# Set target and predictors\n",
    "target = set_target(['yield'])\n",
    "predictors = set_predictors(['uniform_ordered','accepted_first_rank','had_enrolled_sib',\n",
    "                            'orientation_rsvp','virtual_event_attended','in_person_event_attended',\n",
    "                            'scholar_grade','commute_time',\n",
    "                            'utm_source_bucketing','school'])\n",
    "\n",
    "# Prepare data\n",
    "X, y =  setup_training_data(df, predictors, target)\n",
    "X = pd.get_dummies(X, columns=['utm_source_bucketing','school'])\n",
    "x_train, x_test, y_train, y_test =  test_train_split(X, y)\n",
    "x_train = features_to_array(x_train)\n",
    "x_test = features_to_array(x_test)\n",
    "y_train = classes_to_array(y_train)\n",
    "y_test = classes_to_array(y_test)\n",
    "train_data = array_to_tensor(x_train, y_train)\n",
    "\n",
    "# Set weight and bias\n",
    "W = set_weight()\n",
    "b = set_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50, loss: -0.000000, accuracy: 0.745000\n",
      "step: 100, loss: -0.000000, accuracy: 0.690000\n",
      "step: 150, loss: -0.000000, accuracy: 0.705000\n",
      "step: 200, loss: -0.000000, accuracy: 0.705000\n",
      "step: 250, loss: -0.000000, accuracy: 0.745000\n",
      "step: 300, loss: -0.000000, accuracy: 0.705000\n",
      "step: 350, loss: -0.000000, accuracy: 0.715000\n",
      "step: 400, loss: -0.000000, accuracy: 0.715000\n",
      "step: 450, loss: -0.000000, accuracy: 0.730000\n",
      "step: 500, loss: -0.000000, accuracy: 0.735000\n",
      "step: 550, loss: -0.000000, accuracy: 0.770000\n",
      "step: 600, loss: -0.000000, accuracy: 0.735000\n",
      "step: 650, loss: -0.000000, accuracy: 0.745000\n",
      "step: 700, loss: -0.000000, accuracy: 0.755000\n",
      "step: 750, loss: -0.000000, accuracy: 0.690000\n",
      "step: 800, loss: -0.000000, accuracy: 0.745000\n",
      "step: 850, loss: -0.000000, accuracy: 0.770000\n",
      "step: 900, loss: -0.000000, accuracy: 0.705000\n",
      "step: 950, loss: -0.000000, accuracy: 0.755000\n",
      "step: 1000, loss: -0.000000, accuracy: 0.745000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 14:31:15.283345: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    if step % display_step == 0:\n",
    "        pred = logistic_regression(batch_x)\n",
    "        loss = cross_entropy(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.737912\n"
     ]
    }
   ],
   "source": [
    "# Test model on validation set.\n",
    "pred = logistic_regression(x_test)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
